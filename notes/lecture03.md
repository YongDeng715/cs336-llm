# Architecture of LLM & Hyperparameter

[TOC]

## Common Architecture

### normalization

1. Pre-vs-post norm
2. LayerNorm vs RMSNorm

### Activation

GeLU vs SwiGLU

GeLU: Gaussian Error Linear Unit

SwiGLU: Swish-Gated Linear Unit
 
### Position Embedding

RoPE


